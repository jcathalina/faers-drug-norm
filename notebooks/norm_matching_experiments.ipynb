{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d99fa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "from typing import List\n",
    "\n",
    "import requests\n",
    "\n",
    "from requests import Response\n",
    "\n",
    "import time\n",
    "\n",
    "import logging\n",
    "\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21e195ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67d1c5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cleaned:\n",
    "    df = pd.read_csv(\"../data/processed/validated_drugname_list_with_cleaned_col.csv\", usecols=[\"drugname\"])\n",
    "else:\n",
    "    df = pd.read_csv(\"../data/processed/validated_drugname_list.csv\", usecols=[\"drugname\"])\n",
    "     \n",
    "arr = df.to_numpy().astype('str').flatten()\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec165b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def list_chunker(lst: List, chunk_length: int):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), chunk_length):\n",
    "        yield lst[i:i + chunk_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7ed8cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logger = logging.getLogger(\"approx_match\")\n",
    "\n",
    "Candidate = namedtuple('Candidate', ['rxcui', 'score'])\n",
    "\n",
    "\n",
    "class RxNormMatch:\n",
    "    def __init__(self, query: str, candidates: List[Candidate]):\n",
    "        self.query = query\n",
    "        self.candidates = candidates\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Query: {self.query} -- Candidates: {self.candidates}\"\n",
    "\n",
    "    def csv_format(self):\n",
    "        return f\"{self.query},{self.candidates[0].rxcui},{self.candidates[0].score}\\n\"\n",
    "\n",
    "\n",
    "def rxnorm_approx_match(query: str, max_entries=1, sleep_time=1):\n",
    "    candidates: List[Candidate] = []\n",
    "\n",
    "    # TODO: This preprocessing step needs to happen elsewhere, this is just for testing\n",
    "    query = query.replace(\"\\n\", \"\").strip()\n",
    "\n",
    "    url_query: str = query.replace(\" \", \"%\")\n",
    "    response = None\n",
    "    while response is None:\n",
    "        try:\n",
    "            response: Response = requests.get(\n",
    "                f\"http://localhost:4000/REST/approximateTerm.json?term={url_query}&maxEntries={max_entries}\")\n",
    "            break\n",
    "        except Exception:\n",
    "            print(f\"Connection refused by server, sleeping for {sleep_time} seconds...\")\n",
    "            time.sleep(sleep_time)\n",
    "            continue\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Something went wrong... Status code = {response.status_code}\")\n",
    "    j_res = response.json()\n",
    "    try:\n",
    "        j_candidates = j_res[\"approximateGroup\"][\"candidate\"]\n",
    "    except KeyError:\n",
    "        logger.info(f\"Could not find any candidates for query: {query}.\")\n",
    "        return RxNormMatch(query=query, candidates=[Candidate(\"NULL\", 0)])\n",
    "    for j_candidate in j_candidates:\n",
    "        candidates.append(Candidate(j_candidate[\"rxcui\"], int(j_candidate[\"score\"])))\n",
    "    return RxNormMatch(query=query, candidates=candidates)\n",
    "\n",
    "\n",
    "\n",
    "def rxnorm_match(query: str, search_type: int = 1, sleep_time=1):\n",
    "    candidates: List[Candidate] = []\n",
    "\n",
    "    # TODO: This preprocessing step needs to happen elsewhere, this is just for testing\n",
    "    query = query.replace(\"\\n\", \"\").strip()\n",
    "\n",
    "    url_query: str = query.replace(\" \", \"%\")\n",
    "    response = None\n",
    "    while response is None:\n",
    "        try:\n",
    "            response: Response = requests.get(\n",
    "                f\"http://localhost:4000/REST/rxcui.json?name={url_query}&search={search_type}\")\n",
    "            break\n",
    "        except Exception:\n",
    "            # print(f\"Connection refused by server, sleeping for {sleep_time} seconds...\")\n",
    "            time.sleep(sleep_time)\n",
    "            continue\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Something went wrong... Status code = {response.status_code}\")\n",
    "    j_res = response.json()\n",
    "    try:\n",
    "        j_candidates = j_res[\"approximateGroup\"][\"candidate\"]\n",
    "    except KeyError:\n",
    "        logger.info(f\"Could not find any candidates for query: {query}.\")\n",
    "        return RxNormMatch(query=query, candidates=[Candidate(\"NULL\", 0)])\n",
    "    for j_candidate in j_candidates:\n",
    "        candidates.append(Candidate(j_candidate[\"rxcui\"], int(j_candidate[\"score\"])))\n",
    "    return RxNormMatch(query=query, candidates=candidates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c48bf7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(arr):\n",
    "    with open(f\"../output/approx_match_{randint(0,1000)}_brack.csv\", mode=\"w\") as f:\n",
    "        for i in tqdm(arr):\n",
    "            matches = rxnorm_approx_match(query=i)\n",
    "            f.write(matches.csv_format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "901fdf4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11819/11819 [03:14<00:00, 60.74it/s]\n"
     ]
    }
   ],
   "source": [
    "# WORKERS = 1\n",
    "# chunk_len = len(arr) // WORKERS\n",
    "# c = list(list_chunker(lst=arr, chunk_length=chunk_len))\n",
    "\n",
    "# with concurrent.futures.ThreadPoolExecutor(max_workers=WORKERS) as e:\n",
    "#     for result in e.map(run, c):\n",
    "#         pass\n",
    "\n",
    "run(arr[:11819])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132c9edf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
